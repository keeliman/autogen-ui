{
    "llm_config": {
        "seed": 42,
        "temperature": 0.3,
        "use_cache": true,
        "config_list": [
            {
                "model": "gpt-4",
                "api_key": "YOUR_API_KEY_HERE"
            }
        ]
    },
    "user_proxy_config": {
        "human_input_mode": "NEVER",
        "max_consecutive_auto_reply": 10,
        "is_termination_msg": "TERMINATE",
        "code_execution_config": {
            "work_dir": "scratch/coding",
            "use_docker": false
        }
    }
}
